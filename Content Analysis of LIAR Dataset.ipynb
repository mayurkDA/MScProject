{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers\n",
    "pip install keras-tuner\n",
    "pip install tensorflow-addons\n",
    "\n",
    "# Import required packages\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from kerastuner import RandomSearch\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "# Define the file paths\n",
    "train_path = '/content/drive/MyDrive/LIAR Dataset/train.tsv'\n",
    "valid_path = '/content/drive/MyDrive/LIAR Dataset/valid.tsv'\n",
    "test_path = '/content/drive/MyDrive/LIAR Dataset/test.tsv'\n",
    "\n",
    "# Load the datasets\n",
    "liar_train_df = pd.read_csv(train_path, delimiter='\\t', header=None)\n",
    "liar_valid_df = pd.read_csv(valid_path, delimiter='\\t', header=None)\n",
    "liar_test_df = pd.read_csv(test_path, delimiter='\\t', header=None)\n",
    "\n",
    "# Rename the columns for easier reference\n",
    "column_names = [\n",
    "    'JSON_ID', 'Truth_Label', 'Statement_Text', 'Topic',\n",
    "    'Speaker_Name', 'Speaker_Title', 'State_Info', 'Party_Affiliation',\n",
    "    'Total_Credit_History_Count', 'False_Counts', 'Half_True_Counts',\n",
    "    'Mostly_True_Counts', 'Pants_On_Fire_Counts', 'Context'\n",
    "]\n",
    "liar_train_df.columns = column_names\n",
    "liar_valid_df.columns = column_names\n",
    "liar_test_df.columns = column_names\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of truth labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Truth_Label', data=liar_train_df)\n",
    "plt.title('Distribution of Truth Labels in Training Dataset')\n",
    "plt.xlabel('Truth Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = liar_train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = liar_train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values in numerical columns with the column median\n",
    "for col in numerical_cols:\n",
    "    median_value = liar_train_df[col].median()\n",
    "    liar_train_df[col].fillna(median_value, inplace=True)\n",
    "    liar_valid_df[col].fillna(median_value, inplace=True)\n",
    "    liar_test_df[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# Impute missing values in categorical columns with the column mode\n",
    "for col in categorical_cols:\n",
    "    mode_value = liar_train_df[col].mode()[0]\n",
    "    liar_train_df[col].fillna(mode_value, inplace=True)\n",
    "    liar_valid_df[col].fillna(mode_value, inplace=True)\n",
    "    liar_test_df[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Selecting the features for model training\n",
    "textual_feature = 'Statement_Text'\n",
    "numerical_features = ['Total_Credit_History_Count', 'False_Counts', 'Half_True_Counts', 'Mostly_True_Counts', 'Pants_On_Fire_Counts']\n",
    "categorical_feature = 'Party_Affiliation'\n",
    "\n",
    "# Subset the dataframes to include only the selected features\n",
    "train_features_df = liar_train_df[[textual_feature] + numerical_features + [categorical_feature]]\n",
    "valid_features_df = liar_valid_df[[textual_feature] + numerical_features + [categorical_feature]]\n",
    "test_features_df = liar_test_df[[textual_feature] + numerical_features + [categorical_feature]]\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define batch size and maximum sequence length for BERT\n",
    "batch_size = 100\n",
    "max_length = 256\n",
    "\n",
    "# Function to get BERT embeddings for a batch of text\n",
    "def get_bert_embeddings_for_batch(text_batch):\n",
    "    inputs = tokenizer(text_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Initialize lists to hold the BERT embeddings for the training, validation, and test sets\n",
    "bert_embeddings_train = []\n",
    "bert_embeddings_valid = []\n",
    "bert_embeddings_test = []\n",
    "\n",
    "# Loop through the training DataFrame in batches to get embeddings\n",
    "for i in range(0, len(train_features_df), batch_size):\n",
    "    text_batch = train_features_df['Statement_Text'].iloc[i:i+batch_size].tolist()\n",
    "    embeddings_batch = get_bert_embeddings_for_batch(text_batch)\n",
    "    bert_embeddings_train.extend(embeddings_batch)\n",
    "\n",
    "# Loop through the validation DataFrame in batches to get embeddings\n",
    "for i in range(0, len(valid_features_df), batch_size):\n",
    "    text_batch = valid_features_df['Statement_Text'].iloc[i:i+batch_size].tolist()\n",
    "    embeddings_batch = get_bert_embeddings_for_batch(text_batch)\n",
    "    bert_embeddings_valid.extend(embeddings_batch)\n",
    "\n",
    "# Loop through the test DataFrame in batches to get embeddings\n",
    "for i in range(0, len(test_features_df), batch_size):\n",
    "    text_batch = test_features_df['Statement_Text'].iloc[i:i+batch_size].tolist()\n",
    "    embeddings_batch = get_bert_embeddings_for_batch(text_batch)\n",
    "    bert_embeddings_test.extend(embeddings_batch)\n",
    "\n",
    "# Convert lists of embeddings to NumPy arrays\n",
    "bert_embeddings_train = np.array(bert_embeddings_train)\n",
    "bert_embeddings_valid = np.array(bert_embeddings_valid)\n",
    "bert_embeddings_test = np.array(bert_embeddings_test)\n",
    "\n",
    "# Use deep copy to avoid SettingWithCopyWarning\n",
    "train_features_df_copy = train_features_df.copy()\n",
    "valid_features_df_copy = valid_features_df.copy()\n",
    "test_features_df_copy = test_features_df.copy()\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features_df_copy[numerical_features])\n",
    "\n",
    "train_features_df_copy.loc[:, numerical_features] = scaler.transform(train_features_df_copy[numerical_features])\n",
    "valid_features_df_copy.loc[:, numerical_features] = scaler.transform(valid_features_df_copy[numerical_features])\n",
    "test_features_df_copy.loc[:, numerical_features] = scaler.transform(test_features_df_copy[numerical_features])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoder.fit(train_features_df_copy[[categorical_feature]])\n",
    "\n",
    "train_categorical_encoded = encoder.transform(train_features_df_copy[[categorical_feature]])\n",
    "valid_categorical_encoded = encoder.transform(valid_features_df_copy[[categorical_feature]])\n",
    "test_categorical_encoded = encoder.transform(test_features_df_copy[[categorical_feature]])\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_categorical_df = pd.DataFrame(train_categorical_encoded, columns=encoder.get_feature_names_out([categorical_feature]))\n",
    "valid_categorical_df = pd.DataFrame(valid_categorical_encoded, columns=encoder.get_feature_names_out([categorical_feature]))\n",
    "test_categorical_df = pd.DataFrame(test_categorical_encoded, columns=encoder.get_feature_names_out([categorical_feature]))\n",
    "\n",
    "\n",
    "  # Concatenate BERT embeddings, scaled numerical features, and one-hot encoded categorical features\n",
    "  train_final_features = np.hstack([bert_embeddings_train, train_features_df_copy[numerical_features].values, train_categorical_df.values])\n",
    "  valid_final_features = np.hstack([bert_embeddings_valid, valid_features_df_copy[numerical_features].values, valid_categorical_df.values])\n",
    "  test_final_features = np.hstack([bert_embeddings_test, test_features_df_copy[numerical_features].values, test_categorical_df.values])\n",
    "\n",
    "  # Display the shape of the concatenated feature sets to confirm the operation\n",
    "  print(f\"Shape of final training features: {train_final_features.shape}\")\n",
    "  print(f\"Shape of final validation features: {valid_final_features.shape}\")\n",
    "  print(f\"Shape of final test features: {test_final_features.shape}\")\n",
    "\n",
    "# Updated Label Mapping\n",
    "label_mapping = {\n",
    "    'true': 1,\n",
    "    'mostly-true': 0.7,\n",
    "    'half-true': 0.5,\n",
    "    'barely-true': 0.2,\n",
    "    'false': 0,\n",
    "    'pants-fire': -1\n",
    "}\n",
    "\n",
    "# Apply the new mapping to the DataFrame\n",
    "liar_train_df['Truth_Label'] = liar_train_df['Truth_Label'].map(label_mapping)\n",
    "liar_valid_df['Truth_Label'] = liar_valid_df['Truth_Label'].map(label_mapping)\n",
    "liar_test_df['Truth_Label'] = liar_test_df['Truth_Label'].map(label_mapping)\n",
    "\n",
    "# Update the labels arrays\n",
    "train_labels = liar_train_df['Truth_Label'].values\n",
    "valid_labels = liar_valid_df['Truth_Label'].values\n",
    "test_labels = liar_test_df['Truth_Label'].values\n",
    "\n",
    "# Keras Tuner Setup\n",
    "\n",
    "## Define the feature size (number of columns) from the training features\n",
    "feature_size = train_final_features.shape[1]\n",
    "\n",
    "# Function to build model for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(feature_size,)))\n",
    "    model.add(layers.Dense(units=hp.Int('units', min_value=128, max_value=512, step=32), activation='relu'))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(layers.Reshape((hp.Int('units', min_value=128, max_value=512, step=32), 1)))\n",
    "    model.add(Bidirectional(LSTM(hp.Int('lstm_units', min_value=32, max_value=128, step=32))))\n",
    "    model.add(layers.Dense(1))\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG'), weight_decay=1e-5)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(build_model, objective='val_loss', max_trials=5, executions_per_trial=2)\n",
    "tuner.search(train_final_features, train_labels, epochs=5, validation_data=(valid_final_features, valid_labels))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "val_loss_scores = []\n",
    "val_mae_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_final_features):\n",
    "    X_train_fold, X_val_fold = train_final_features[train_index], train_final_features[val_index]\n",
    "    y_train_fold, y_val_fold = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "    model = build_model(best_hp)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    val_loss, val_mae = model.evaluate(X_val_fold, y_val_fold)\n",
    "    val_loss_scores.append(val_loss)\n",
    "    val_mae_scores.append(val_mae)\n",
    "\n",
    "avg_val_loss = np.mean(val_loss_scores)\n",
    "avg_val_mae = np.mean(val_mae_scores)\n",
    "\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation MAE: {avg_val_mae}\")\n",
    "\n",
    "# Plot Training & Validation Loss Values vs Epoch\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss vs Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.test_mae = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x, y = self.test_data\n",
    "        loss, mae = self.model.evaluate(x, y, verbose=0)\n",
    "        self.test_mae.append(mae)\n",
    "        self.test_loss.append(loss)\n",
    "        print(f'Test MAE: {mae}, Test Loss: {loss}')\n",
    "\n",
    "# Initialize EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Initialize custom TestCallback\n",
    "test_callback = TestCallback((test_final_features, test_labels))\n",
    "\n",
    "# Train the final model\n",
    "final_model = build_model(best_hp)\n",
    "history = final_model.fit(\n",
    "    train_final_features, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_data=(valid_final_features, valid_labels),\n",
    "    callbacks=[early_stop, test_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_mae = final_model.evaluate(valid_final_features, valid_labels, batch_size=64)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation MAE: {val_mae}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = final_model.evaluate(test_final_features, test_labels, batch_size=64)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Training and Validation MAE over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
